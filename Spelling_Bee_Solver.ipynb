{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling Bee Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using two word lists (big.txt and words-1.txt), an initial set of letters, and a designated center letter, I created a [NY Spelling Bee](https://www.nytimes.com/puzzles/spelling-bee) solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening files\n",
    "big_file = open('word-files/big.txt').read() #The Adventures of Sherlock Holmes a large book with lots of words\n",
    "word_file = open('word-files/words-1.txt').read() #A file with lots of words\n",
    "\n",
    "#combining these two giant corpuses will create the word list I will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he imagination.\"\\n\\n\"A proposition which I took the liberty of doubting.\"\\n\\n\"You did, Doctor, but none the less you must come round to my view, for otherwise I shall keep on piling fact upon fact on you until your reason breaks down under them and acknowledges me to be right. Now, Mr. Jabez Wilson here has been good enough to call upon me this morning, and to begin a narrative which promises to be one of the most singular which I have listened to for some time. You have heard me remark that the strangest and most unique things are very often connected not with the larger but with the smaller crimes, and occasionally, indeed, where there is room for doubt whether any positive crime has been committed. As far as I have heard, it is impossible for me to say whether the present case is an instance of crime or not, but the course of events is certainly among the most singular that I have ever listened to. Perhaps, Mr. Wilson, you would have the great kindness to recommence your narrative. I as'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_file[50000:51000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#big file cleaning\n",
    "\n",
    "#lowercase all words\n",
    "big_file = big_file.lower()\n",
    "\n",
    "#creating a list of words\n",
    "big_file = big_file.split()\n",
    "\n",
    "#removing non-alpha words\n",
    "big_file = {item for item in big_file if item.isalpha()}\n",
    "\n",
    "#removing duplicates\n",
    "big_file = set(big_file)\n",
    "\n",
    "#big file contains this many word\n",
    "len(big_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalmous\\nalmsdeed\\nalmsfolk\\nalmsful\\nalmsgiver\\nalmsgiving\\nalmshouse\\nalmsman\\nalmswoman\\nalmucantar\\nalmuce\\nalmud\\nalmude\\nalmug\\nalmuten\\nalnage\\nalnager\\nalnagership\\nalnein\\nalnico\\nalniresinol\\nalniviridol\\nalnoite\\nalnuin\\nalochia\\nalodial\\nalodialism\\nalodialist\\nalodiality\\nalodially\\nalodian\\nalodiary\\nalodification\\nalodium\\nalody\\naloed\\naloelike\\naloemodin\\naloeroot\\naloesol\\naloeswood\\naloetic\\naloetical\\naloewood\\naloft\\nalogia\\nalogical\\nalogically\\nalogism\\nalogy\\naloid\\naloin\\naloisiite\\naloma\\nalomancy\\nalone\\naloneness\\nalong\\nalongshore\\nalongshoreman\\nalongside\\nalongst\\naloof\\naloofly\\naloofness\\naloose\\nalopecia\\nalopecist\\nalopecoid\\nalopeke\\nalose\\nalouatte\\naloud\\nalowe\\nalpaca\\nalpasotes\\nalpeen\\nalpenglow\\nalpenhorn\\nalpenstock\\nalpenstocker\\nalpestral\\nalpestrian\\nalpestrine\\nalpha\\nalphabet\\nalphabetarian\\nalphabetic\\nalphabetical\\nalphabetically\\nalphabetics\\nalphabetiform\\nalphabetism\\nalphabetist\\nalphabetization\\nalphabetize\\nalphabetizer\\nalphatoluic\\nalphenic\\nalphitomancy\\nalphitomorphous\\nalphol\\nalphorn\\nalphos\\nalphosis\\nalphyl\\nalpieu\\nalpigene\\nal'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_file[50000:51000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning word file\n",
    "\n",
    "#creating word file list\n",
    "word_file = word_file.split()\n",
    "\n",
    "#removing duplicate words and changing to set\n",
    "word_file = set(word_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'aalii', 'aardvark', 'aardwolf', 'aaron']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Union all words together to create a list of all acceptable words\n",
    "all_words = set.union(big_file, word_file)\n",
    "\n",
    "sorted(all_words)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut down to just words four letters or longer\n",
    "valid_words = []\n",
    "not_valid_words = []\n",
    "\n",
    "for word in all_words:\n",
    "    if len(word) > 3:\n",
    "        valid_words.append(word)\n",
    "    else:\n",
    "        not_valid_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spelling bee solver\n",
    "\n",
    "import string\n",
    "def NYSpellingBee(optional_letters, required_letter):\n",
    "    \n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "   \n",
    "    optional_letters.append(required_letter)\n",
    "    letters_not_used = [letter for letter in alphabet if letter not in optional_letters]\n",
    "    acceptable_words = []\n",
    "    \n",
    "    for word in valid_words:\n",
    "        if required_letter in word:\n",
    "            if any(letter in letters_not_used for letter in word) == False:\n",
    "                acceptable_words.append(word)\n",
    "                    \n",
    "    return sorted(acceptable_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adaunt',\n",
       " 'adnoun',\n",
       " 'ahunt',\n",
       " 'anahau',\n",
       " 'anounou',\n",
       " 'aoudad',\n",
       " 'ataunt',\n",
       " 'auhuhu',\n",
       " 'aunt',\n",
       " 'aunthood',\n",
       " 'daunt',\n",
       " 'daunton',\n",
       " 'duhat',\n",
       " 'handout',\n",
       " 'haunt',\n",
       " 'hound',\n",
       " 'houtou',\n",
       " 'hunt',\n",
       " 'nandu',\n",
       " 'naunt',\n",
       " 'noun',\n",
       " 'nunhood',\n",
       " 'nutant',\n",
       " 'outdo',\n",
       " 'outhunt',\n",
       " 'outhut',\n",
       " 'tahua',\n",
       " 'tatou',\n",
       " 'taunt',\n",
       " 'thou',\n",
       " 'thud',\n",
       " 'tout',\n",
       " 'tuath',\n",
       " 'tundun',\n",
       " 'tunna',\n",
       " 'unadd',\n",
       " 'undah',\n",
       " 'undo',\n",
       " 'undon',\n",
       " 'unhad',\n",
       " 'unhand',\n",
       " 'unhat',\n",
       " 'unhaunt',\n",
       " 'unhood',\n",
       " 'unhot',\n",
       " 'unna',\n",
       " 'untaut',\n",
       " 'unto',\n",
       " 'untooth',\n",
       " 'utah']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing solver\n",
    "optional_letters = ['a','o','h','t','n','d']\n",
    "required_letter = 'u'\n",
    "NYSpellingBee(optional_letters, required_letter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
